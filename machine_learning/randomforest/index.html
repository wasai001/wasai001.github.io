<!DOCTYPE html>
<html>
  <head>
    
    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-138240662-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>
      
  Introduction of Random Forest (RF) Algorithm &ndash; Big Data Time

    </title>
    
    
    <meta name="description" property="og:description" content="With excellent performance on all eight metrics, calibrated boosted trees were the best learning algorithm overall. Random forests are close second, followed by uncalibrated bagged trees, calibrated SVMs, and un- calibrated neural nets.
​ &amp;ndash; Rich Caruana, Alexandru Niculescu-Mizil
link: https://www.cs.cornell.edu/~caruana/ctp/ct.papers/caruana.icml06.pdf
 Definition Decision Tree is a schematic, tree-shaped diagram used to determine a course of action or show a statistical probability. Each branch of the decision tree represents a possible decision, occurrence or reaction.|">
    

    <meta name="apple-mobile-web-app-title" content="Big Data Time">
    
    
    
    


    <link rel="stylesheet" href="/assets/syntax.css">
    <link rel="stylesheet" href="/assets/primer-build.css">
    <link rel="stylesheet" href="/assets/style.css">
  </head>


  <body class="bg-gray">
    <div id="holy" class="container-lg bg-white h-100">

      <div id="header" class="px-1 bg-white">
        <nav class="UnderlineNav UnderlineNav--right px-2">
  <a class="UnderlineNav-actions muted-link h2" href="https://wasai001.github.io/">
    Big Data Time
  </a>

  
  
  <div class="UnderlineNav-body">
    
    
    <a class="UnderlineNav-item " href="/machine_learning/">
      
      <span>machine learning / ai</span>
    </a>
    
    
    
    <a class="UnderlineNav-item " href="/programming/">
      
      <span>programming</span>
    </a>
    
    
    
    <a class="UnderlineNav-item " href="/statistics/">
      
      <span>statistics</span>
    </a>
    
    
    
    <a class="UnderlineNav-item " href="/visualization/">
      
      <span>visualization</span>
    </a>
    
    
    
    <a class="UnderlineNav-item " href="/about/">
      
      <span>about site</span>
    </a>
    
    
  </div>
  
</nav>

      </div>

      <div role="main" id="main" class="holy-main markdown-body px-4 bg-white">
        

<div class="Subhead">
  <div class="Subhead-heading">
    <div class="h1 mt-3 mb-1">Introduction of Random Forest (RF) Algorithm</div>
  </div>
  <div class="Subhead-description">
    




<a href='/tags/mahine-learning' class="muted-link">
  <span class="Label Label--gray">Mahine Learning</span>
</a>



    
    <div class="float-md-right">
      <span title="Lastmod: 2019-08-11. Published at: 2019-08-11.">
        
          Published: 2019-08-11
        
      </span>
    </div>
    
  </div>
</div>
<article>
  
  <section class="pb-6 mb-3 border-bottom">
    

<blockquote>
<p>With excellent performance on all eight metrics, calibrated boosted trees were the best learning algorithm overall. Random forests are close second, followed by uncalibrated bagged trees, calibrated SVMs, and un- calibrated neural nets.</p>

<p>​                                                                                                         &ndash; Rich Caruana, Alexandru Niculescu-Mizil</p>

<p>link: <a href="https://www.cs.cornell.edu/~caruana/ctp/ct.papers/caruana.icml06.pdf">https://www.cs.cornell.edu/~caruana/ctp/ct.papers/caruana.icml06.pdf</a></p>
</blockquote>

<h2 id="definition">Definition</h2>

<p><strong>Decision Tree</strong> is a schematic, tree-shaped diagram used to determine a course of action or show a statistical probability. Each branch of the decision tree represents a possible decision, occurrence or reaction. The tree is structured to show how and why one choice may lead to the next, with the use of the branches indicating each option is mutually exclusive.</p>

<p><strong>Random Forests</strong> are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest.</p>

<h2 id="splitting-criteria">Splitting Criteria</h2>

<ul>
<li>Information Gain</li>
<li>Entropy Gain</li>
<li>Variance</li>
<li>Gini Index (Binary only)</li>
<li>Chi Square</li>
<li>Etc</li>
</ul>

<p><strong>Example of Good Split and Bad Split</strong></p>

<p><img src="https://www.aunalytics.com/wp-content/uploads/2015/01/DecisionTree_BlogImages_1-15-03.png" alt="Gini Coefficient illustration" /></p>

<h2 id="algorithm">Algorithm</h2>

<p><strong>Random Forest for Regression or Classification</strong></p>

<p>1 For t = 1 to B: (Construct B trees)</p>

<p>1.1 Choose a bootstrap sample D(t) from D of size N from the training data.</p>

<p>1.2 Grow a random-forest tree T(i) to the bootstrapped data, by recursively repeating the following steps for each leaf node of the tree, until the minimum node size n(min) is reached.</p>

<p>1.2.1 Select m variables at random from the M variables</p>

<p>1.2.2 Pick the best variable/split-point among the m.</p>

<p>1.2.3 Split the node into two daughter nodes</p>

<p>2 Output the ensemble of trees {Tb}^B(1)</p>

<h2 id="visualization-of-bagging">Visualization of Bagging</h2>

<p><img src="https://slideplayer.com/slide/5051116/16/images/2/General+Idea.jpg" alt="img" /></p>

<h2 id="visualization-of-bootstrapping">Visualization of Bootstrapping</h2>

<p><img src="https://raw.githubusercontent.com/wasai001/wasai001.github.io/master/img/randomforest-boostrapping.png" alt="" /></p>

<h2 id="building-a-forest-with-ensenble">Building a Forest with Ensenble</h2>

<p><img src="https://raw.githubusercontent.com/wasai001/wasai001.github.io/master/img/randomforest-ensemble.png" alt="" /></p>

<h2 id="advantage-of-random-forest">Advantage of Random Forest</h2>

<ul>
<li>Can solve both type of problems, classification and regression</li>
<li>Random forests generalize well to new data</li>
<li>It is unexcelled in accuracy among current algorithms</li>
<li>It runs efficiently on large data bases and can handle thousands of input variables without variable
deletion</li>
<li>It gives estimates of what variables are important in the classification</li>
<li>It generates an internal unbiased estimate of the generalization error as the forest building progresses</li>
<li>It has an effective method for estimating missing data and maintains accuracy when a large proportion
of the data are missing</li>
<li>It computes proximities between pairs of cases that can be used in clustering, locating outliers, or give
interesting views of the data</li>
<li>Out-of-bag error estimate removes the need for a set aside test set</li>
</ul>

<h2 id="disadvantage-of-random-forest">Disadvantage of Random Forest</h2>

<ul>
<li>The results are less actionable because forests are not easily interpreted. Considered black box  approach for statistical modelers with little control on what the model does. Similar to a Neural Network.</li>
<li>It surely does a good job at classification but not as good as for regression problem as it does not give precise continuous nature predictions. In case of regression, it doesn’t predict beyond the range in the training data, and that they may over-fit data sets that are particularly noisy.</li>
</ul>

<h2 id="apply-in-python">Apply in Python</h2>

<pre><code class="language-python"># Import the model we are using
from sklearn.ensemble import RandomForestRegressor

# Instantiate model with 1000 decision trees
rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)

# Train the model on training data
rf.fit(train_features, train_labels);

# Use the forest's predict method on the test data
predictions = rf.predict(test_features)

# Calculate the absolute errors
errors = abs(predictions - test_labels)

# Print out the mean absolute error (mae)
print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')

Mean Absolute Error: 3.83 degrees.

# Calculate mean absolute percentage error (MAPE)
mape = 100 * (errors / test_labels)

# Calculate and display accuracy
accuracy = 100 - np.mean(mape)
print('Accuracy:', round(accuracy, 2), '%.')

Accuracy: 93.99 %.
</code></pre>

<h2 id="apply-in-r">Apply in R</h2>

<pre><code class="language-r">install.packages(&quot;randomForest&quot;)
library(randomForest)
	
# Create a Random Forest model with default parameters
model1 &lt;- randomForest(Condition ~ ., data = TrainSet, importance = TRUE)
model1

# Fine tuning parameters of Random Forest model
model2 &lt;- randomForest(Condition ~ ., data = TrainSet, ntree = 500, mtry = 6, importance = TRUE)
model2

# Predicting on train set
predTrain &lt;- predict(model2, TrainSet, type = &quot;class&quot;)

# Checking classification accuracy
table(predTrain, TrainSet$Condition)  
</code></pre>

  </section>

  <section>
    
      
    
  </section>
</article>

      </div>

      <div id="side" class="pr-1 bg-white">
        <aside class="pr-3">
          
  
    <div id="toc" class="Box Box--blue mb-3">
      <b>Introduction of Random Forest (RF) Algorithm</b>
      <nav id="TableOfContents">
<ul>
<li>
<ul>
<li><a href="#definition">Definition</a></li>
<li><a href="#splitting-criteria">Splitting Criteria</a></li>
<li><a href="#algorithm">Algorithm</a></li>
<li><a href="#visualization-of-bagging">Visualization of Bagging</a></li>
<li><a href="#visualization-of-bootstrapping">Visualization of Bootstrapping</a></li>
<li><a href="#building-a-forest-with-ensenble">Building a Forest with Ensenble</a></li>
<li><a href="#advantage-of-random-forest">Advantage of Random Forest</a></li>
<li><a href="#disadvantage-of-random-forest">Disadvantage of Random Forest</a></li>
<li><a href="#apply-in-python">Apply in Python</a></li>
<li><a href="#apply-in-r">Apply in R</a></li>
</ul></li>
</ul>
</nav>
    </div>
  

  
    <div>
      
    </div>
  

        </aside>
      </div>

      <div id="footer" class="pt-2 pb-3 bg-white text-center">
        

  <span class="text-small text-gray">
    &copy;Everything here is mine 2019 &middot; 

    Powered by the
    <a href="https://github.com/qqhann/hugo-primer" class="link-gray-dark">Hugo-Primer</a> theme for
    <a href="https://gohugo.io" class="link-gray-dark">Hugo</a>.
  </span>


      </div>
    </div>


    
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/x-mathjax-config">MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });</script>
  </body>
</html>
